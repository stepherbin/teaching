{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c83f09",
   "metadata": {},
   "source": [
    "# Détection de Fake News\n",
    "\n",
    "L'objectif est de prédire si des déclarations sont vraies ou fausses.\n",
    "\n",
    "Les données sont celles de la base LIAR2\n",
    "\n",
    "- accessible depuis Hugging Face: https://huggingface.co/datasets/chengxuphd/liar2 \n",
    "- ou depuis le Github https://github.com/chengxuphd/liar2 qui contient des codes et des références.\n",
    "\n",
    "## Les données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f60f76",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "\n",
    "Depuis Hugging-Face\n",
    "\n",
    "Les données sont organisées en dictionnaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b788a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datasets\n",
    "dataset = \"chengxuphd/liar2\"\n",
    "dataset = datasets.load_dataset(dataset)\n",
    "statement_train, y_train = dataset[\"train\"][\"statement\"], dataset[\"train\"][\"label\"]\n",
    "statement_val, y_val = dataset[\"validation\"][\"statement\"], dataset[\"validation\"][\"label\"]\n",
    "statement_test, y_test = dataset[\"test\"][\"statement\"], dataset[\"test\"][\"label\"]\n",
    "\n",
    "output_tags = [\"Pants on fire\",\"False\",\"Barely-true\",\"Half-true\",\"Mostly-true\",\"True\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5bb307",
   "metadata": {},
   "source": [
    "Depuis le Github de LIAR2\n",
    "\n",
    "Les données sont téléchargées en fichier 'csv' et lus avec pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f8a121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-23 16:23:28--  https://raw.githubusercontent.com/chengxuphd/liar2/refs/heads/main/liar2/train.csv\n",
      "Resolving proxy.onera (proxy.onera)... 125.1.1.78\n",
      "Connecting to proxy.onera (proxy.onera)|125.1.1.78|:80... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 19041186 (18M) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>]  18.16M  56.5MB/s    in 0.3s    \n",
      "\n",
      "2025-12-23 16:23:29 (56.5 MB/s) - ‘train.csv’ saved [19041186/19041186]\n",
      "\n",
      "--2025-12-23 16:23:29--  https://raw.githubusercontent.com/chengxuphd/liar2/refs/heads/main/liar2/test.csv\n",
      "Resolving proxy.onera (proxy.onera)... 125.1.1.78\n",
      "Connecting to proxy.onera (proxy.onera)|125.1.1.78|:80... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 2384586 (2.3M) [text/plain]\n",
      "Saving to: ‘test.csv’\n",
      "\n",
      "test.csv            100%[===================>]   2.27M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-12-23 16:23:30 (21.5 MB/s) - ‘test.csv’ saved [2384586/2384586]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if (not os.path.exists('train.csv')):\n",
    "  !wget https://raw.githubusercontent.com/chengxuphd/liar2/refs/heads/main/liar2/train.csv\n",
    "if (not os.path.exists('test.csv')):\n",
    "  !wget https://raw.githubusercontent.com/chengxuphd/liar2/refs/heads/main/liar2/test.csv\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b0b0c",
   "metadata": {},
   "source": [
    "### Nettoyage des données\n",
    "\n",
    "Les fonctions ci-dessous transforment les données brutes en une séquence de mots normalisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f48e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /d/herbin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /d/herbin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /d/herbin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /d/herbin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /d/herbin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "# Interactive library download\n",
    "#nltk.download()\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# ensure NLTK resources available\n",
    "nltk_packages = [\"punkt\", \"stopwords\", \"wordnet\", \"omw-1.4\"]\n",
    "for pkg in nltk_packages:\n",
    "    try:\n",
    "        nltk.data.find(pkg)\n",
    "    except LookupError:\n",
    "        nltk.download(pkg)\n",
    "\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Basic cleanup: lowercase, remove urls, punctuation, extra spaces, stopwords, lemmatize.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 1]\n",
    "    tokens = [LEMMATIZER.lemmatize(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "statement_train_clean = list(map(clean_text, statement_train))\n",
    "statement_val_clean = list(map(clean_text, statement_val))\n",
    "statement_test_clean = list(map(clean_text, statement_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39e9c6",
   "metadata": {},
   "source": [
    "### Génération des labels\n",
    "\n",
    "Les données d'origine sont définies par un score de véracité à 6 niveaux.\n",
    "\n",
    "Ici on transforme le problème en une classification binaire (\"true\", \"Fake\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbffab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = np.array([0 if i <= 2 else 1 for i in y_test])\n",
    "y_train_binary = np.array([0 if i <= 2 else 1 for i in y_train])\n",
    "y_val_binary = np.array([0 if i <= 2 else 1 for i in y_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ef151",
   "metadata": {},
   "source": [
    "## Premiers tests\n",
    "\n",
    "### Transformation des données\n",
    "\n",
    "Les déclarations sont des listes de taille variable.\n",
    "\n",
    "On les transforme en vecteurs de taille fixe par la méthode des \"bag of words\", dans sa version Tf-Idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39033e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données sont de dimension 10000\n",
      "Le nombre de données d'apprentissage est 18369\n",
      "Le nombre moyen de valeurs non nulles par échantillon est 12.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train = vec.fit_transform(statement_train_clean)\n",
    "X_test = vec.transform(statement_test_clean)\n",
    "\n",
    "print(\"Les données sont de dimension {:d}\".format(X_train.shape[1]))\n",
    "print(\"Le nombre de données d'apprentissage est {:d}\".format(y_train_binary.shape[0]))\n",
    "\n",
    "# Calcul du nombre moyens d'éléments non nuls\n",
    "non_nul_moyen = np.mean(np.sum(X_train > 0,axis=1))\n",
    "print(\"Le nombre moyen de valeurs non nulles par échantillon est {:.1f}\".format(non_nul_moyen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4c7eb",
   "metadata": {},
   "source": [
    "### Essais élémentaire de classification\n",
    "\n",
    "Le code ci-dessous teste différents algorithmes du cours pour la classification binaire, avec leurs paramètres par défaut.\n",
    "\n",
    "C'est une première base, clairement à améliorer.\n",
    "\n",
    "En particulier, on peut utiliser un modèle de langage pour encoder les déclarations et travailler sur cette représentatino plutôt que sur le \"bag of words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6746f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreurs de train/test pour le modèle MultinomialNB() est 23.21 / 32.40%\n",
      "Erreurs de train/test pour le modèle LinearSVC(C=0.1, max_iter=10000) est 21.68 / 31.53%\n",
      "Erreurs de train/test pour le modèle LogisticRegression(max_iter=1000) est 21.37 / 31.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "model_list = [MultinomialNB(), \n",
    "              LinearSVC(max_iter=10000, C=0.1), \n",
    "              LogisticRegression(max_iter=1000), \n",
    "            #   RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "              ]\n",
    "\n",
    "for model in model_list:\n",
    "    model.fit(X_train, y_train_binary)\n",
    "    preds = model.predict(X_train)\n",
    "\n",
    "    print(\"Erreurs de train/test pour le modèle {} est {:.2f} / {:.2f}%\".format(\n",
    "        model, \n",
    "        100*(1-model.score(X_train, y_train_binary)), \n",
    "        100*(1-model.score(X_test, y_test_binary))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37d140",
   "metadata": {},
   "source": [
    "### Autres informations utilisables\n",
    "\n",
    "Le jeu de données contient en plus de la déclaration (\"statement\") et de sa valeur de vérité (\"label\") des informations sur la data, le sujet, l'orateur, sa description, le lieu, le contexte de la déclaration, et une justification du score. Il contient aussi un historique pour chaque orateur de la véracité de ses déclarations ('counts').\n",
    "\n",
    "Elle peuvent être utilisées pour améliorer la prédiction en exploitant les bons priors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9c7092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_description</th>\n",
       "      <th>state_info</th>\n",
       "      <th>true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_false_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13847</td>\n",
       "      <td>5</td>\n",
       "      <td>90 percent of Americans \"support universal bac...</td>\n",
       "      <td>October 2, 2017</td>\n",
       "      <td>government regulation;polls and public opinion...</td>\n",
       "      <td>chris abele</td>\n",
       "      <td>Chris Abele is Milwaukee County Executive, a p...</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>a tweet</td>\n",
       "      <td>\"Universal\" is the term for background checks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13411</td>\n",
       "      <td>1</td>\n",
       "      <td>Last year was one of the deadliest years ever ...</td>\n",
       "      <td>May 19, 2017</td>\n",
       "      <td>after the fact;congress;criminal justice;histo...</td>\n",
       "      <td>thom tillis</td>\n",
       "      <td>Thom Tillis is a Republican who serves as U.S....</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a press release supporting the Back The Blue A...</td>\n",
       "      <td>Sen. Thom Tillis, a North Carolina Republican,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10882</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernie Sanders's plan is \"to raise your taxes ...</td>\n",
       "      <td>October 28, 2015</td>\n",
       "      <td>taxes</td>\n",
       "      <td>chris christie</td>\n",
       "      <td>Chris Christie announced June 6, 2023 that he ...</td>\n",
       "      <td>national</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>Boulder, Colo</td>\n",
       "      <td>Christie said that Sanders’s plan is \"to raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20697</td>\n",
       "      <td>4</td>\n",
       "      <td>Voter ID is supported by an overwhelming major...</td>\n",
       "      <td>December 8, 2021</td>\n",
       "      <td>voter id laws</td>\n",
       "      <td>lee zeldin</td>\n",
       "      <td>Lee Zeldin is a Republican representing New Yo...</td>\n",
       "      <td>new york</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a Tweet</td>\n",
       "      <td>Zeldin claimed voter identification requiremen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6095</td>\n",
       "      <td>2</td>\n",
       "      <td>Says Barack Obama \"robbed Medicare (of) $716 b...</td>\n",
       "      <td>August 12, 2012</td>\n",
       "      <td>federal budget;history;medicare;retirement</td>\n",
       "      <td>mitt romney</td>\n",
       "      <td>Mitt Romney is a U.S. senator from Utah. He ra...</td>\n",
       "      <td>national</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>an interview on \"60 Minutes\"</td>\n",
       "      <td>Romney said, \"There's only one president that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                          statement  \\\n",
       "0  13847      5  90 percent of Americans \"support universal bac...   \n",
       "1  13411      1  Last year was one of the deadliest years ever ...   \n",
       "2  10882      0  Bernie Sanders's plan is \"to raise your taxes ...   \n",
       "3  20697      4  Voter ID is supported by an overwhelming major...   \n",
       "4   6095      2  Says Barack Obama \"robbed Medicare (of) $716 b...   \n",
       "\n",
       "               date                                            subject  \\\n",
       "0   October 2, 2017  government regulation;polls and public opinion...   \n",
       "1      May 19, 2017  after the fact;congress;criminal justice;histo...   \n",
       "2  October 28, 2015                                              taxes   \n",
       "3  December 8, 2021                                      voter id laws   \n",
       "4   August 12, 2012         federal budget;history;medicare;retirement   \n",
       "\n",
       "          speaker                                speaker_description  \\\n",
       "0     chris abele  Chris Abele is Milwaukee County Executive, a p...   \n",
       "1     thom tillis  Thom Tillis is a Republican who serves as U.S....   \n",
       "2  chris christie  Chris Christie announced June 6, 2023 that he ...   \n",
       "3      lee zeldin  Lee Zeldin is a Republican representing New Yo...   \n",
       "4     mitt romney  Mitt Romney is a U.S. senator from Utah. He ra...   \n",
       "\n",
       "       state_info  true_counts  mostly_true_counts  half_true_counts  \\\n",
       "0       wisconsin            1                   4                 5   \n",
       "1  north carolina            0                   2                 7   \n",
       "2        national           21                  20                27   \n",
       "3        new york            1                   2                 0   \n",
       "4        national           31                  33                58   \n",
       "\n",
       "   mostly_false_counts  false_counts  pants_on_fire_counts  \\\n",
       "0                    3             5                     2   \n",
       "1                    3             2                     0   \n",
       "2                   11            17                     8   \n",
       "3                    0             0                     0   \n",
       "4                   35            32                    19   \n",
       "\n",
       "                                             context  \\\n",
       "0                                            a tweet   \n",
       "1  a press release supporting the Back The Blue A...   \n",
       "2                                      Boulder, Colo   \n",
       "3                                            a Tweet   \n",
       "4                       an interview on \"60 Minutes\"   \n",
       "\n",
       "                                       justification  \n",
       "0  \"Universal\" is the term for background checks ...  \n",
       "1  Sen. Thom Tillis, a North Carolina Republican,...  \n",
       "2  Christie said that Sanders’s plan is \"to raise...  \n",
       "3  Zeldin claimed voter identification requiremen...  \n",
       "4  Romney said, \"There's only one president that ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "print(dataset['train'])\n",
    "for i in range(4):\n",
    "    print('statement: ', dataset['train']['statement'][i])\n",
    "    print('speaker: ', dataset['train']['speaker'][i])\n",
    "    print('speaker description: ', dataset['train']['speaker_description'][i])\n",
    "    print('context: ', dataset['train']['context'][i])\n",
    "    print('justification: ', dataset['train']['justification'][i])\n",
    "    print('')\n",
    "'''\n",
    "\n",
    "df_train.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepCuda12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
